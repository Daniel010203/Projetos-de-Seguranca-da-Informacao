import requests
from bs4 import BeautifulSoup
import operator
from collections import Counter


def start(url):
    wordlist = []
    source_code = requests.get(url).text

    soup = BeautifulSoup(source_code, 'html.parser')

    # Text in given web-page is stored under
    # the <div> tags with class <entry-content>
    for each_text in soup.findAll('div', {'class': 'entry-content'}):
        content = each_text.text

        words = content.lower().split()

        for each_word in words:
            wordlist.append(each_word)
        clean_wordlist(wordlist)


def clean_wordlist(wordlist):
    clean_list = []
    for word in wordlist:
        symbols = ' @#$%^&*()_-+={[}]|\;:"<>?/., '

        for i in range(0, len(symbols)):
            word = word.replace(symbols[i], '')

        if len(word) > 0:
            clean_list.append(word)
    create_dictionary(clean_list)


def create_dictionary(clean_list):
    word_count = {}

    for word in clean_list:
        if word in word_count:
            word_count[word] += 1
        else:
            word_count[word] = 1

    for key, value in sorted(word_count.items(),
                             key=operator.itemgetter(1)):
        print("% s : % s " % (key, value))

    c = Counter(word_count)

    top = c.most_common(10)
    print(top)


if __name__ == '__main__':
    start("https://www.geeksforgeeks.org/python-programming-language/?ref=leftbar")


EXPLICAÇÃO DO CÓDIGO:
Este código realiza a análise de frequência de palavras em um site específico, extraindo o conteúdo de texto de determinadas tags HTML, limpando e contando as palavras. Vou explicar cada parte do código:

import requests: Importa o módulo requests, que é utilizado para enviar requisições HTTP.

from bs4 import BeautifulSoup: Importa a classe BeautifulSoup do módulo bs4, que é uma biblioteca em Python para puxar dados de HTML e XML.

import operator: Importa o módulo operator, que fornece funções que implementam operadores padrão do Python.

from collections import Counter: Importa a classe Counter do módulo collections, que é utilizada para contar a ocorrência de elementos em uma lista.

def start(url): Define uma função chamada start que recebe uma URL como argumento. Essa função é responsável por iniciar o processo de análise.

wordlist = []: Inicializa uma lista vazia chamada wordlist para armazenar as palavras extraídas do site.

source_code = requests.get(url).text: Faz uma requisição GET para a URL fornecida e obtém o conteúdo HTML da página.

soup = BeautifulSoup(source_code, 'html.parser'): Cria um objeto BeautifulSoup chamado soup para analisar o conteúdo HTML.

A partir daqui, o código usa soup.findAll para encontrar todas as instâncias de <div> com a classe entry-content no HTML. Em seguida, ele itera sobre essas instâncias, extrai o texto, converte para minúsculas, divide em palavras e adiciona essas palavras à lista wordlist.

clean_wordlist(wordlist): Chama a função clean_wordlist passando a lista wordlist como argumento.

def clean_wordlist(wordlist): Define uma função chamada clean_wordlist que recebe uma lista de palavras como argumento. Essa função remove caracteres especiais de cada palavra e chama a função create_dictionary passando a lista limpa como argumento.

create_dictionary(clean_list): Define uma função chamada create_dictionary que cria um dicionário de contagem de palavras e imprime as palavras ordenadas por frequência. Em seguida, utiliza a classe Counter para contar as palavras e imprimir as 10 palavras mais comuns.

if __name__ == '__main__':: Verifica se o script está sendo executado diretamente (não importado como um módulo).

start("https://www.geeksforgeeks.org/python-programming-language/?ref=leftbar"): Chama a função start com a URL específica do GeeksforGeeks como argumento para iniciar o processo de análise.
